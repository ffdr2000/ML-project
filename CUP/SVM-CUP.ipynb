{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn import metrics \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUP SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "path=r'/home/ludovico/ML-project/data/cup/ML-CUP23-'\n",
    "train_set = pd.read_csv(path+'TR.csv',skiprows=7, header=None, delimiter=',', dtype=str)\n",
    "\n",
    "input=train_set[train_set.columns[1:-3]]\n",
    "target=train_set[train_set.columns[-3:]]\n",
    "\n",
    "#splitting design set from test set (test set will be used only for the final model assessment)\n",
    "#the random seed is fixed to use the same design set for all the models\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(input, target, test_size=0.2, random_state=0, shuffle=True)\n",
    "\n",
    "x_train=x_train.astype(np.float64)\n",
    "y_train=y_train.astype(np.float64)\n",
    "\n",
    "\n",
    "#we add this metric (Mean euclidean error) to evaluate the performance of the model \n",
    "def MEE(x, y):\n",
    "    return np.mean(np.linalg.norm(x - y, 2, axis=1))\n",
    "\n",
    "#list to choose the best kernel for the SVR model\n",
    "best_model_kernel=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM RBF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the validation error (MEE) varying the hyperparameters to choose the best\n",
    "We fix 2 different epsilon and 3 different gamma varying C in a logarithmically spaced range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1,(12,4))\n",
    "\n",
    "C=np.logspace(0,4,30)\n",
    "epsilon=[0.1,0.5]\n",
    "for eps in epsilon:\n",
    "\n",
    "    g=[0.01,0.2,5]\n",
    "    for i,gamma in enumerate(g):\n",
    "        parameters_SVM = {\n",
    "        'estimator__C':C,\n",
    "        'estimator__kernel': ['rbf'],\n",
    "        'estimator__gamma':[gamma],\n",
    "        'estimator__epsilon':[eps],\n",
    "        'estimator__max_iter':[1000000]\n",
    "    }\n",
    "        grid_search_SVM = GridSearchCV(\n",
    "        estimator=MultiOutputRegressor(SVR()),\n",
    "        param_grid=parameters_SVM,\n",
    "        cv=RepeatedKFold(n_splits=5, n_repeats=5, random_state=0),\n",
    "        n_jobs=-1,\n",
    "        return_train_score = True,\n",
    "        scoring=make_scorer(MEE, greater_is_better=False),\n",
    "    )\n",
    "            \n",
    "        SVM=grid_search_SVM.fit(x_train, y_train)\n",
    "        cv_results_df = pd.DataFrame(grid_search_SVM.cv_results_)\n",
    "        error=cv_results_df['mean_test_score'].values\n",
    "        plt.subplot(1,len(g),i+1)\n",
    "        #plt.subplots_adjust(wspace=0)\n",
    "        if i==0:\n",
    "            plt.ylabel('MEE validation')\n",
    "        plt.title(r'$\\gamma$='+str(gamma))\n",
    "        plt.errorbar(C,-error,marker='.',label=r'$\\epsilon$='+str(eps),linestyle='')\n",
    "        plt.xlabel('C')\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(0.5,40)\n",
    "        plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final grid search for SVM RBF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_SVM= {\n",
    "    'estimator__C': [10,100,1000,10000,20000],\n",
    "    'estimator__kernel': ['rbf'],\n",
    "    'estimator__gamma':[0.01,0.1,0.2,1],\n",
    "    'estimator__epsilon': [0.1,0.3],\n",
    "    'estimator__max_iter': [100000] \n",
    "}      \n",
    "\n",
    "# with GridSearch\n",
    "grid_search_SVM = GridSearchCV(\n",
    "    estimator=MultiOutputRegressor(SVR()),\n",
    "    param_grid=parameters_SVM,\n",
    "    refit=True,\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    return_train_score = True,\n",
    "    scoring=make_scorer(MEE, greater_is_better=False),\n",
    ")\n",
    "\n",
    "SVM_rbf=grid_search_SVM.fit(x_train, y_train)\n",
    "best_model_kernel.append(SVM_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(SVM_rbf.cv_results_)\n",
    "best_model_index=SVM_rbf.best_index_\n",
    "\n",
    "print('best params', SVM_rbf.best_params_) \n",
    "\n",
    "val_loss=cv_results_df['mean_test_score'][best_model_index]\n",
    "val_std=cv_results_df['std_test_score'][best_model_index]\n",
    "train_loss=cv_results_df['mean_train_score'][best_model_index]\n",
    "train_std=cv_results_df['std_train_score'][best_model_index]\n",
    "print('Train loss:',train_loss,'+/-', train_std)\n",
    "print('Validation loss:',val_loss,'+/-', val_std)\n",
    "\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for SVM poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C=np.logspace(0,4,5)\n",
    "\n",
    "gamma=np.logspace(-2,2,5)\n",
    "\n",
    "coef=np.linspace(0,10,3)\n",
    "\n",
    "deg=np.arange(2,6,3)\n",
    "\n",
    "parameters_SVM= {\n",
    "    'estimator__C':C,\n",
    "    'estimator__kernel': ['poly'],\n",
    "    'estimator__gamma':gamma,\n",
    "    'estimator__coef0':coef ,\n",
    "    'estimator__degree':[5] ,\n",
    "    'estimator__epsilon': [0.1],\n",
    "    'estimator__max_iter':[1000] \n",
    "}      \n",
    "\n",
    "# with GridSearch\n",
    "grid_search_SVM = GridSearchCV(\n",
    "    estimator=MultiOutputRegressor(SVR()),\n",
    "    param_grid=parameters_SVM,\n",
    "    refit=True,\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    return_train_score = True,\n",
    "    scoring=make_scorer(MEE, greater_is_better=False),\n",
    ")\n",
    "\n",
    "SVM_poly=grid_search_SVM.fit(x_train, y_train)\n",
    "best_model_kernel.append(SVM_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(SVM_poly.cv_results_)\n",
    "best_model_index=SVM_poly.best_index_\n",
    "\n",
    "print('best params', SVM_poly.best_params_) \n",
    "\n",
    "val_loss=cv_results_df['mean_test_score'][best_model_index]\n",
    "val_std=cv_results_df['std_test_score'][best_model_index]\n",
    "train_loss=cv_results_df['mean_train_score'][best_model_index]\n",
    "train_std=cv_results_df['std_train_score'][best_model_index]\n",
    "print('Train loss:',train_loss,'+/-', train_std)\n",
    "print('Validation loss:',val_loss,'+/-', val_std)\n",
    "\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the validation error (MEE) varying the hyperparameters to choose the best\n",
    "We fix 3 different beta0 (coef0) and 3 different beta1(gamma) varying C in a logarithmically spaced range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=np.logspace(-3,4,40)\n",
    "\n",
    "plt.figure(1,(12,4))\n",
    "coef=[-5,-4,-3]\n",
    "for c in coef:\n",
    "\n",
    "    g=[0.01,0.1,0.5]\n",
    "    for i,gamma in enumerate(g):\n",
    "        parameters_SVM= {\n",
    "        'estimator__C':C ,\n",
    "        'estimator__kernel': ['sigmoid'],\n",
    "        'estimator__gamma': [gamma],\n",
    "        'estimator__coef0':[c],\n",
    "        'estimator__epsilon': [eps],\n",
    "        }\n",
    "        grid_search_SVM = GridSearchCV(\n",
    "        estimator=MultiOutputRegressor(SVR()),\n",
    "        param_grid=parameters_SVM,\n",
    "        cv=RepeatedKFold(n_splits=5, n_repeats=1, random_state=0),\n",
    "        n_jobs=-1,\n",
    "        return_train_score = True,\n",
    "        scoring=make_scorer(MEE, greater_is_better=False),\n",
    "        )\n",
    "            \n",
    "        SVM=grid_search_SVM.fit(x_train, y_train)\n",
    "        cv_results_df = pd.DataFrame(grid_search_SVM.cv_results_)\n",
    "        error=cv_results_df['mean_test_score'].values\n",
    "        plt.subplot(1,len(g),i+1)\n",
    "        \n",
    "        if i==0:\n",
    "            plt.ylabel('MEE validation')\n",
    "        plt.title(r'$\\beta_0$='+str(gamma))\n",
    "        plt.errorbar(C,-error,marker='.',label=r'$\\beta_1$='+str(c),linestyle='')\n",
    "        plt.xlabel('C')\n",
    "        plt.yscale('log')\n",
    "        plt.xscale('log')\n",
    "        plt.ylim(0.1,10000)\n",
    "        plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final grid search for SVM sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coef=np.linspace(-5,-2,4)\n",
    "\n",
    "\n",
    "parameters_SVM= {\n",
    "    'estimator__C':[100,1000,10000,50000],\n",
    "    'estimator__kernel': ['sigmoid'],\n",
    "    'estimator__gamma': [0.1,0.3],\n",
    "    'estimator__coef0':coef,\n",
    "    'estimator__epsilon': [0.1],\n",
    "}      \n",
    "\n",
    "# with GridSearch\n",
    "grid_search_SVM = GridSearchCV(\n",
    "    estimator=MultiOutputRegressor(SVR()),\n",
    "    param_grid=parameters_SVM,\n",
    "    refit=True,\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=10, random_state=0),\n",
    "    n_jobs=-1,\n",
    "    return_train_score = True,\n",
    "    scoring=make_scorer(MEE, greater_is_better=False),\n",
    ")\n",
    "\n",
    "SVM_sigmoid=grid_search_SVM.fit(x_train, y_train)\n",
    "best_model_kernel.append(SVM_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(SVM_sigmoid.cv_results_)\n",
    "best_model_index=SVM_sigmoid.best_index_\n",
    "\n",
    "print('best params', SVM_sigmoid.best_params_) \n",
    "\n",
    "val_loss=cv_results_df['mean_test_score'][best_model_index]\n",
    "val_std=cv_results_df['std_test_score'][best_model_index]\n",
    "train_loss=cv_results_df['mean_train_score'][best_model_index]\n",
    "train_std=cv_results_df['std_train_score'][best_model_index]\n",
    "print('Train loss:',train_loss,'+/-', train_std)\n",
    "print('Validation loss:',val_loss,'+/-', val_std)\n",
    "\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model selection \n",
    "The best model among the three kernel is the one with the lowest MEE score on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc=[]\n",
    "for model in best_model_kernel:\n",
    "    val_acc.append(model.best_score_)\n",
    "\n",
    "SVM=best_model_kernel[np.argmax(np.array(val_acc))]\n",
    "\n",
    "print('best params:',SVM.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
